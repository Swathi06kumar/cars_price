# -*- coding: utf-8 -*-
"""carprice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sBJzeVFeDV61EMz4XU-LU3kDIE23Qqmk
"""

import pandas as pd
import numpy as np
df = pd.read_csv('cars_price.csv')
df

df.shape

df.describe()

df.info()

df=df.replace('?',np.nan)
df

df.isnull().sum()

df.dropna(inplace=True)
df.reset_index(drop=True)

df.head()

X=df.iloc[:,1:]
y=df.iloc[:,0]

"""visualization**"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.pairplot(df)
plt.show()

def dummies(x,df):
    temp = pd.get_dummies(df[x], drop_first = True)
    df = pd.concat([df, temp], axis = 1)
    df.drop([x], axis = 1, inplace = True)
    return df
# Applying the function to the cars_lr
df = dummies('make',df)
df = dummies('fuel-type',df)
df = dummies('aspiration',df)
df = dummies('num-of-doors',df)
df = dummies('body-style',df)
df = dummies('drive-wheels',df)
df = dummies('engine-location',df)
df = dummies('fuel-system',df)
df = dummies('engine-type',df)
df = dummies('num-of-cylinders',df)

first_column = df.pop('price')
  

df.insert(0, 'price', first_column)
df=df.drop(["porsche"],axis=1)

df

X=df.iloc[:,1:]
y=df.iloc[:,0]

"""Train_Test_Split"""

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

"""Model Building

1.Linear *Regresion*
"""

from sklearn.linear_model import LinearRegression

linreg=LinearRegression(positive=bool,)
linreg.fit(X_train,y_train)
LinearRegression()

linreg.score(X_train,y_train)

linreg.score(X_test,y_test)

"""2.Decision Tree"""

from sklearn.tree import DecisionTreeRegressor

dtc=DecisionTreeRegressor(max_depth=10,random_state=10)

dtc.fit(X_train,y_train)

print(dtc.score(X_train,y_train))

print(dtc.score(X_test,y_test))

"""3.Random **Forest**"""

from sklearn.ensemble import RandomForestRegressor

rfr=RandomForestRegressor(max_depth=10,random_state=10)

rfr.fit(X_train,y_train)

print(rfr.score(X_train,y_train))

print(rfr.score(X_test,y_test))

"""4.Ridge *Regression*"""

from sklearn.linear_model import Ridge

Ridge=Ridge()

Ridge.fit(X_train,y_train)

print(Ridge.score(X_train,y_train))

print(Ridge.score(X_test,y_test))

"""5.Lasso **Regression**"""

from sklearn import linear_model

clf = linear_model.Lasso(alpha=0.1)

clf.fit(X_train,y_train)

print(clf.score(X_train,y_train))

print(clf.score(X_test,y_test))

"""Final_Model

Ridge *Regression* ( Ridge Regression gives the best scores,so i selected it as my final model
"""

from sklearn.linear_model import Ridge

Ridge=Ridge()

Ridge.fit(X_train,y_train)

print(Ridge.score(X_train,y_train))

print(Ridge.score(X_test,y_test))

"""Mean Squared  Error


"""

from sklearn.metrics import mean_squared_error

y_pred=Ridge.predict(X_test)
mean_squared_error(y_test,y_pred)

"""Median Absolute **Error**"""

from sklearn.metrics import median_absolute_error

y_pred=Ridge.predict(X_test)

median_absolute_error(y_test, y_pred)

"""R2 Score"""

from sklearn.metrics import r2_score

r2_score(y_test,y_pred)